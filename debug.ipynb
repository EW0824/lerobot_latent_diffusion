{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check dataset action dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "Number of episodes: 800\n",
      "Features: {'observation.image': {'dtype': 'video', 'shape': (84, 84, 3), 'names': ['height', 'width', 'channel'], 'video_info': {'video.fps': 15.0, 'video.codec': 'av1', 'video.pix_fmt': 'yuv420p', 'video.is_depth_map': False, 'has_audio': False}}, 'observation.state': {'dtype': 'float32', 'shape': (4,), 'names': {'motors': ['motor_0', 'motor_1', 'motor_2', 'motor_3']}}, 'action': {'dtype': 'float32', 'shape': (4,), 'names': {'motors': ['motor_0', 'motor_1', 'motor_2', 'motor_3']}}, 'episode_index': {'dtype': 'int64', 'shape': (1,), 'names': None}, 'frame_index': {'dtype': 'int64', 'shape': (1,), 'names': None}, 'timestamp': {'dtype': 'float32', 'shape': (1,), 'names': None}, 'next.reward': {'dtype': 'float32', 'shape': (1,), 'names': None}, 'next.done': {'dtype': 'bool', 'shape': (1,), 'names': None}, 'index': {'dtype': 'int64', 'shape': (1,), 'names': None}, 'task_index': {'dtype': 'int64', 'shape': (1,), 'names': None}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from lerobot.common.datasets import LeRobotDataset\n",
    "ds = LeRobotDataset(\"lerobot/xarm_lift_medium\")\n",
    "\n",
    "ds.download_episodes()\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Dataset info:\")\n",
    "print(f\"Number of episodes: {ds.num_episodes}\")\n",
    "print(f\"Features: {ds.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First item keys: dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'index', 'task_index', 'task'])\n",
      "\n",
      "Trying to access episodes...\n",
      "Successfully collected 5 actions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[57261]: Class AVFFrameReceiver is implemented in both /Users/OAA/miniforge3/envs/robotics/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11bd083a8) and /Users/OAA/miniforge3/envs/robotics/lib/libavdevice.61.3.100.dylib (0x16bb4c848). One of the two will be used. Which one is undefined.\n",
      "objc[57261]: Class AVFAudioReceiver is implemented in both /Users/OAA/miniforge3/envs/robotics/lib/python3.10/site-packages/av/.dylibs/libavdevice.61.3.100.dylib (0x11bd083f8) and /Users/OAA/miniforge3/envs/robotics/lib/libavdevice.61.3.100.dylib (0x16bb4c898). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "# Try to access a single episode first\n",
    "try:\n",
    "    # Get the first item from the dataset\n",
    "    first_item = ds[0]\n",
    "    print(\"\\nFirst item keys:\", first_item.keys())\n",
    "    \n",
    "    # Now try to access episodes\n",
    "    print(\"\\nTrying to access episodes...\")\n",
    "    all_actions = []\n",
    "    for i in range(min(5, ds.num_episodes)):  # Try first 5 episodes\n",
    "        item = ds[i]\n",
    "        if \"action\" in item:\n",
    "            all_actions.append(item[\"action\"])\n",
    "    \n",
    "    print(f\"Successfully collected {len(all_actions)} actions\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Mean: [ 0.27324945 -0.14783773 -0.15354335 -0.23991735]\n",
      "Action Std: [0.631202   0.6673078  0.6527433  0.65370834]\n",
      "Action Min: [-1. -1. -1. -1.]\n",
      "Action Max: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "all_actions = []\n",
    "for episode in ds:\n",
    "    # print(episode)\n",
    "    all_actions.append(episode[\"action\"])\n",
    "    # for step in episode:\n",
    "    #     print(step)\n",
    "    #     all_actions.append(step[\"action\"])\n",
    "\n",
    "actions = np.array(all_actions)\n",
    "\n",
    "print(\"Action Mean:\", actions.mean(axis=0))\n",
    "print(\"Action Std:\", actions.std(axis=0))\n",
    "print(\"Action Min:\", actions.min(axis=0))\n",
    "print(\"Action Max:\", actions.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Diffusion + VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lerobot.common.policies.diffusion.modeling_diffusion import DiffusionPolicy\n",
    "from lerobot.common.policies.diffusion.configuration_diffusion import DiffusionConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device 'None' is not available. Switching to 'mps'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must provide at least one image or the environment state among the inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mlatent_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m      3\u001b[0m config\u001b[38;5;241m.\u001b[39mvae_ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/vae_ckpt.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43mDiffusionPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m policy\u001b[38;5;241m.\u001b[39mvae\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(config\u001b[38;5;241m.\u001b[39mvae_ckpt))\n\u001b[1;32m      8\u001b[0m policy\u001b[38;5;241m.\u001b[39mvae\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/188_project/lerobot_latent_diffusion/lerobot/common/policies/diffusion/modeling_diffusion.py:70\u001b[0m, in \u001b[0;36mDiffusionPolicy.__init__\u001b[0;34m(self, config, dataset_stats)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    config: Policy configuration class instance or None, in which case the default instantiation of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m        that they will be passed with a call to `load_state_dict` before the policy is used.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_inputs \u001b[38;5;241m=\u001b[39m Normalize(config\u001b[38;5;241m.\u001b[39minput_features, config\u001b[38;5;241m.\u001b[39mnormalization_mapping, dataset_stats)\n",
      "File \u001b[0;32m~/Desktop/188_project/lerobot_latent_diffusion/lerobot/common/policies/diffusion/configuration_diffusion.py:208\u001b[0m, in \u001b[0;36mDiffusionConfig.validate_features\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalidate_features\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_features) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv_state_feature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide at least one image or the environment state among the inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, image_ft \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_features\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mValueError\u001b[0m: You must provide at least one image or the environment state among the inputs."
     ]
    }
   ],
   "source": [
    "config = DiffusionConfig()\n",
    "config.latent_dim = 4\n",
    "config.vae_ckpt = \"checkpoints/vae_ckpt.pth\"\n",
    "\n",
    "policy = DiffusionPolicy(config)\n",
    "\n",
    "policy.vae.load_state_dict(torch.load(config.vae_ckpt))\n",
    "policy.vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
